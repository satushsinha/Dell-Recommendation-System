# -*- coding: utf-8 -*-
"""webscraping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wkf3Cyt43Q71tJmYRKyuPHvY9jEpHydO
"""

from selenium import webdriver
from bs4 import BeautifulSoup
import pandas as pd

pip install beautifulsoup4

pip install selenium

!apt-get update 
!apt install chromium-chromedriver

from selenium import webdriver
chrome_options = webdriver.ChromeOptions()
chrome_options.add_argument('--headless')
chrome_options.add_argument('--no-sandbox')
chrome_options.add_argument('--disable-dev-shm-usage')
wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)
driver =webdriver.Chrome('chromedriver',chrome_options=chrome_options)

driver =webdriver.Chrome('chromedriver',chrome_options=chrome_options)

products=[] #List to store name of the product
prices=[] #List to store price of the product
ratings=[] #List to store rating of the product
descriptions=[] #List to store the description of the product
href_list=[]
reviews=[]

driver.get("https://www.flipkart.com/laptops/pr?sid=6bo%2Cb5g&p%5B%5D=facets.brand%255B%255D%3DDell&pageUID=1591709957426&otracker=clp_metro_expandable_2_26.metroExpandable.METRO_EXPANDABLE_Dell_laptops-store_ATZ0N15AZUUY_wp14&fm=neo%2Fmerchandising&iid=M_07916983-2010-4298-b0c9-9491ce5ad282_26.ATZ0N15AZUUY&ppt=clp&ppn=laptops-store&ssid=8af9ufbjkw0000001599985602004&page=2")

content = driver.page_source
soup = BeautifulSoup(content)
for a in soup.findAll('a', href=True , attrs={'class':'_31qSD5'}):
  name=a.find('div',{'class':'_3wU53n'})
  price=a.find('div', attrs={'class':'_1vC4OE _2rQ-NK'})
  description=a.find('div', attrs={'class':'_3ULzGw'})
  rating=a.find('div', attrs={'class':'hGSR34'})

  products.append(name.text)
  prices.append(price.text)
  descriptions.append(description.text)
  try:
    ratings.append(rating.text)
  except:
    ratings.append(0)

len(prices)

for a in soup.findAll('a', href=True , attrs={'class':'_31qSD5'}):
  href_list.append(a['href'])

len(href_list)

for i in href_list:

  driver.get("https://www.flipkart.com" + i)
  try:
    driver.find_elements_by_class_name("_1EPkIx")[0].click()
  except:
    continue
  content = driver.page_source
  soup = BeautifulSoup(content)
  try:
    reviews.append(soup.find('div', attrs={'class':'qwjRop'}).text)
  except:
    reviews.append("No reviews for this Laptop")

len(reviews)

reviews

df = pd.DataFrame({'Product Name':products,'Price':prices,'Features':descriptions, 'Rating':ratings, 'Review':reviews})
df.to_csv('products.csv', index=False, encoding='utf-8')